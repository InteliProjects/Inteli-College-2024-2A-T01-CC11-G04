{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1wxmQQRmibKeY7AA_fbSWtyn4jplicC7O",
      "authorship_tag": "ABX9TyNskQEomGMV9HkNgLgOA+i/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Inteli-College/2024-2A-T01-CC11-G04/blob/62-atualizao-da-pipeline-de-processamento/notebooks/sprint3/word_correction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4JCrlVFV-TdA"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download pt_core_news_sm -q"
      ],
      "metadata": {
        "id": "5LjWrmJdA3Is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"pt_core_news_sm\")"
      ],
      "metadata": {
        "id": "o82MqUOs-sxA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teste com `Pyspellchecker`"
      ],
      "metadata": {
        "id": "VB2s9dkXD98J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspellchecker -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2YKsrU7_Jc6",
        "outputId": "0764b824-e3a4-43ea-d4eb-564e75ec9581"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Downloading pyspellchecker-0.8.1-py3-none-any.whl (6.8 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/6.8 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spellchecker import SpellChecker\n",
        "import re"
      ],
      "metadata": {
        "id": "1mFa9t1dAvUQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all available directories\n",
        "dir(SpellChecker)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1owcUxErBKb4",
        "outputId": "a408d285-9844-4021-91c6-c416ba4a97ce"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_SpellChecker__edit_distance_alt',\n",
              " '__class__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '_case_sensitive',\n",
              " '_check_if_should_check',\n",
              " '_distance',\n",
              " '_tokenizer',\n",
              " '_word_frequency',\n",
              " 'candidates',\n",
              " 'correction',\n",
              " 'distance',\n",
              " 'edit_distance_1',\n",
              " 'edit_distance_2',\n",
              " 'export',\n",
              " 'known',\n",
              " 'languages',\n",
              " 'split_words',\n",
              " 'unknown',\n",
              " 'word_frequency',\n",
              " 'word_usage_frequency']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spell = SpellChecker(language='pt')"
      ],
      "metadata": {
        "id": "CQxgKxhRBUD8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docx = \"Oi, td bem? Eu axo q a gnt pode ir amanha pro lugar q vc falou. Tb qro mto ver se consseguimos resolver isso logo pq ta demorando d+. Vc pode me confirma se vai da certo?\""
      ],
      "metadata": {
        "id": "DWsz6evyBwR7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docx = re.findall(\"[a-zA-Z]+\", docx)\n",
        "print(docx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt_BExzUBdsI",
        "outputId": "00072c39-3910-4b3b-9a7a-9bf8be5e651e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Oi', 'td', 'bem', 'Eu', 'axo', 'q', 'a', 'gnt', 'pode', 'ir', 'amanha', 'pro', 'lugar', 'q', 'vc', 'falou', 'Tb', 'qro', 'mto', 'ver', 'se', 'consseguimos', 'resolver', 'isso', 'logo', 'pq', 'ta', 'demorando', 'd', 'Vc', 'pode', 'me', 'confirma', 'se', 'vai', 'da', 'certo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(docx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85jWzY3xCRjJ",
        "outputId": "8993735c-c45f-45b5-8527-8e7efa96a8da"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(docx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWKaMwVoC-6f",
        "outputId": "82d0a668-6ac0-4e6e-93c8-12d0bba05545"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "misspelled = spell.unknown(docx)"
      ],
      "metadata": {
        "id": "p5raSMspB9vA"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(misspelled))\n",
        "print(misspelled)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_MGfsK0ChIt",
        "outputId": "0fccd1d7-040d-4ec8-c446-bf46959b9d36"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "{'q', 'd', 'axo', 'td', 'oi', 'gnt', 'tb', 'mto', 'pq', 'qro', 'consseguimos', 'vc'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in misspelled:\n",
        "  print(f\"Palavra incorreta: \\\"{word}\\\" sugestão:,\\\"{spell.correction(word)}\\\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOtgms30Da5_",
        "outputId": "8913a323-1ea2-44b3-fa64-4a9c31ac05b8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palavra incorreta: \"q\" sugestão:,\"a\"\n",
            "Palavra incorreta: \"d\" sugestão:,\"a\"\n",
            "Palavra incorreta: \"axo\" sugestão:,\"ao\"\n",
            "Palavra incorreta: \"td\" sugestão:,\"te\"\n",
            "Palavra incorreta: \"oi\" sugestão:,\"o\"\n",
            "Palavra incorreta: \"gnt\" sugestão:,\"no\"\n",
            "Palavra incorreta: \"tb\" sugestão:,\"te\"\n",
            "Palavra incorreta: \"mto\" sugestão:,\"mão\"\n",
            "Palavra incorreta: \"pq\" sugestão:,\"pé\"\n",
            "Palavra incorreta: \"qro\" sugestão:,\"pro\"\n",
            "Palavra incorreta: \"consseguimos\" sugestão:,\"conseguimos\"\n",
            "Palavra incorreta: \"vc\" sugestão:,\"vi\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teste com `Hunspell`"
      ],
      "metadata": {
        "id": "qENKRn3sEFZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install hunspell\n",
        "!apt-get install hunspell-pt-br"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-I4Lf1PEI6d",
        "outputId": "76efb2c0-7c11-4d8a-f89f-591c46e0e5cd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  dictionaries-common hunspell-en-us libhunspell-1.7-0 libtext-iconv-perl\n",
            "Suggested packages:\n",
            "  wordlist openoffice.org-hunspell | openoffice.org-core\n",
            "The following NEW packages will be installed:\n",
            "  dictionaries-common hunspell hunspell-en-us libhunspell-1.7-0 libtext-iconv-perl\n",
            "0 upgraded, 5 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 723 kB of archives.\n",
            "After this operation, 2,412 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtext-iconv-perl amd64 1.7-7build3 [14.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 dictionaries-common all 1.28.14 [185 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 hunspell-en-us all 1:2020.12.07-2 [280 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhunspell-1.7-0 amd64 1.7.0-4build1 [175 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 hunspell amd64 1.7.0-4build1 [67.9 kB]\n",
            "Fetched 723 kB in 1s (956 kB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package libtext-iconv-perl.\n",
            "(Reading database ... 123597 files and directories currently installed.)\n",
            "Preparing to unpack .../libtext-iconv-perl_1.7-7build3_amd64.deb ...\n",
            "Unpacking libtext-iconv-perl (1.7-7build3) ...\n",
            "Selecting previously unselected package dictionaries-common.\n",
            "Preparing to unpack .../dictionaries-common_1.28.14_all.deb ...\n",
            "Adding 'diversion of /usr/share/dict/words to /usr/share/dict/words.pre-dictionaries-common by dictionaries-common'\n",
            "Unpacking dictionaries-common (1.28.14) ...\n",
            "Selecting previously unselected package hunspell-en-us.\n",
            "Preparing to unpack .../hunspell-en-us_1%3a2020.12.07-2_all.deb ...\n",
            "Unpacking hunspell-en-us (1:2020.12.07-2) ...\n",
            "Selecting previously unselected package libhunspell-1.7-0:amd64.\n",
            "Preparing to unpack .../libhunspell-1.7-0_1.7.0-4build1_amd64.deb ...\n",
            "Unpacking libhunspell-1.7-0:amd64 (1.7.0-4build1) ...\n",
            "Selecting previously unselected package hunspell.\n",
            "Preparing to unpack .../hunspell_1.7.0-4build1_amd64.deb ...\n",
            "Unpacking hunspell (1.7.0-4build1) ...\n",
            "Setting up libtext-iconv-perl (1.7-7build3) ...\n",
            "Setting up dictionaries-common (1.28.14) ...\n",
            "Setting up hunspell-en-us (1:2020.12.07-2) ...\n",
            "Setting up libhunspell-1.7-0:amd64 (1.7.0-4build1) ...\n",
            "Setting up hunspell (1.7.0-4build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "Processing triggers for dictionaries-common (1.28.14) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libreoffice-writer\n",
            "The following NEW packages will be installed:\n",
            "  hunspell-pt-br\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 1,218 kB of archives.\n",
            "After this operation, 5,865 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 hunspell-pt-br all 1:7.2.0-2 [1,218 kB]\n",
            "Fetched 1,218 kB in 1s (1,766 kB/s)\n",
            "Selecting previously unselected package hunspell-pt-br.\n",
            "(Reading database ... 123693 files and directories currently installed.)\n",
            "Preparing to unpack .../hunspell-pt-br_1%3a7.2.0-2_all.deb ...\n",
            "Unpacking hunspell-pt-br (1:7.2.0-2) ...\n",
            "Setting up hunspell-pt-br (1:7.2.0-2) ...\n",
            "Processing triggers for dictionaries-common (1.28.14) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hunspell"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aIpy3-dF2y3",
        "outputId": "347ccea5-003e-4dd2-ec66-6eda9df78f6e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hunspell\n",
            "  Downloading hunspell-0.5.5.tar.gz (34 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: hunspell\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for hunspell (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for hunspell\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for hunspell\n",
            "Failed to build hunspell\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (hunspell)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tentar realizar a instalação localmente"
      ],
      "metadata": {
        "id": "Olu7H-1CGXa6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teste com `LanguageTool`"
      ],
      "metadata": {
        "id": "DOqvN4umGUme"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEoglxsRGWjX",
        "outputId": "b7afee33-35e2-4354-a16a-d64d284962b2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Texto com erros ortográficos e gramaticais\n",
        "docx = \"Oi, td bem? Eu axo q a gnt pode ir amanha pro lugar q vc falou. Tb qro mto ver se consseguimos resolver isso logo pq ta demorando d+. Vc pode me confirma se vai da certo?\"\n",
        "\n",
        "# Endpoint da API pública do LanguageTool\n",
        "url = \"https://api.languagetool.org/v2/check\"\n",
        "\n",
        "# Parâmetros para a requisição (incluindo o texto e o idioma)\n",
        "data = {\n",
        "    'text': docx,\n",
        "    'language': 'pt-BR'\n",
        "}\n",
        "\n",
        "# Enviar requisição para a API\n",
        "response = requests.post(url, data=data)\n",
        "\n",
        "# Analisar a resposta\n",
        "result = response.json()\n",
        "\n",
        "# Mostrar os erros e sugestões de correção\n",
        "for match in result['matches']:\n",
        "    print(f\"Erro: {match['context']['text']}\")\n",
        "\n",
        "    # Extrair sugestões de correção (acessando o campo 'value' dentro do dicionário)\n",
        "    suggestions = [suggestion['value'] for suggestion in match['replacements']]\n",
        "\n",
        "    # Mostrar as 2 primeiras sugestões\n",
        "    if suggestions:\n",
        "        print(f\"Sugestão: {', '.join(suggestions[0:2])}\")\n",
        "    else:\n",
        "        print(\"Nenhuma sugestão encontrada.\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MaO0RgkGcBh",
        "outputId": "845574e7-2ba0-4d28-c421-11e4a559ee64"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erro: Oi, td bem? Eu axo q a gnt pode ir amanha pro ...\n",
            "Sugestão: TV, CD\n",
            "\n",
            "Erro: Oi, td bem? Eu axo q a gnt pode ir amanha pro lugar q vc f...\n",
            "Sugestão: achou, acho\n",
            "\n",
            "Erro: Oi, td bem? Eu axo q a gnt pode ir amanha pro lugar q vc fal...\n",
            "Sugestão: que, \"q\"\n",
            "\n",
            "Erro: Oi, td bem? Eu axo q a gnt pode ir amanha pro lugar q vc falou. Tb...\n",
            "Sugestão: CNT, GT\n",
            "\n",
            "Erro: Oi, td bem? Eu axo q a gnt pode ir amanha pro lugar q vc falou. Tb qro mto ver se...\n",
            "Sugestão: amanhã\n",
            "\n",
            "Erro: ..., td bem? Eu axo q a gnt pode ir amanha pro lugar q vc falou. Tb qro mto ver se con...\n",
            "Sugestão: para o\n",
            "\n",
            "Erro: ...Eu axo q a gnt pode ir amanha pro lugar q vc falou. Tb qro mto ver se consseguimo...\n",
            "Sugestão: que, \"q\"\n",
            "\n",
            "Erro: ... axo q a gnt pode ir amanha pro lugar q vc falou. Tb qro mto ver se consseguimos r...\n",
            "Sugestão: você\n",
            "\n",
            "Erro: ...nt pode ir amanha pro lugar q vc falou. Tb qro mto ver se consseguimos resolver is...\n",
            "Sugestão: Também\n",
            "\n",
            "Erro: ...pode ir amanha pro lugar q vc falou. Tb qro mto ver se consseguimos resolver isso l...\n",
            "Sugestão: pró, pro\n",
            "\n",
            "Erro: ... ir amanha pro lugar q vc falou. Tb qro mto ver se consseguimos resolver isso logo ...\n",
            "Sugestão: no, não\n",
            "\n",
            "Erro: ...pro lugar q vc falou. Tb qro mto ver se consseguimos resolver isso logo pq ta demorando d+. ...\n",
            "Sugestão: conseguimos, conseguímos\n",
            "\n",
            "Erro: ... ver se consseguimos resolver isso logo pq ta demorando d+. Vc pode me confirma se...\n",
            "Sugestão: porque, por que\n",
            "\n",
            "Erro: ... resolver isso logo pq ta demorando d+. Vc pode me confirma se vai da certo?\n",
            "Sugestão: Você\n",
            "\n"
          ]
        }
      ]
    }
  ]
}